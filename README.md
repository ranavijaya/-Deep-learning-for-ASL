## Abstract

ASL word is performed by an ASL signer, based on the acoustic images
provided in the dataset, using Convolutional neural network as the classifier

## 1 Dataset

This dataset includes 10 ASLwords performedby 5 subjects. In this dataset, all images are
generated by using the short-time Fourier transform(STFT) to calculate a spectrogram as the
feature representation of the reflected near-ultrasound waves. This dataset has a training set of
5,000 examples, and a test set of 1,000 examples.

For our model we transformed our images by 32*32 .This reduced our training time a lot.

We used a custom image loader, which automatically read images from the pictures folder.

## 2 Building Neural Network

In this part, we build a Convolutional Neural Network with 2 hidden layers, 2 convolutional layer
and a max pool followed by each convolutional layer.

*2.1Training the Neural Network*

On training our aforementioned neural network we were able to achieve validation accuracy of
88% in 13 epochs. We used early stopping, and stopped training once we had >85% validation
accuracy.

*2.2Testing the Neural Network*

In this part, we test the neural network on the test set and we get test *accuracy* of *80.5%*.

This can be further improved by regularization.

*2.3 L1 Regularization*

*Experimental setup* : Here, we added L2 regularizationin the loss function by adding the l
norms of the conv2D layers to the model.

We used early stopping, and stopped training once we had >85% validation accuracy.

We added L1 regularization to our model structure in the Conv2D layer and achieved validation
*accuracy* of *88%* in 11 epochs.

*Results:*
On evaluating this model on the test set we received *accuracy* of: *82%. This **accuracy* is slightly
better than what we achieved without any regularization.

*2.4 L2 Regularization*

*Experimental setup* : Here, we added L2 regularizationin the loss function by adding the l
norms of the conv2D layers to the model.

We used early stopping, and stopped training once we had >85% validation accuracy.

We obtained the validation *accuracy* of *86.2%*.

*Results*

Thetest *accuracy* isobtainedas *85.05%* .This *accuracy* isbetterthanL1aswellas *accuracy*
without any regularization.

We observed that L2 regularization further
improves model *accuracy* and performance.

*2.5 Dropout Regularization*

*Experimental setup* :

We implemented the dropout regularization by adding a dropout layer just before the output **with
25% dropout** , keeping the model architecture almostsame and achieved validation accuracy of
*85.5%* in 10 epochs.


*Results:*

The test *accuracy* we obtained is *84%* .This is better than what we did insection 2.1 and L1
regularization but slightly worse than L2.


## 3 Resnet 50

In this part,we loaded the pre-trained model Resnet-50 for the imageNet dataset. We added a
trainable fully connected layer (output layer for our usecase). We trained the resnet model by
freezing a different number of layers each time.Training resnet was quite long so we limited our
training to 10 epochs.We also used early stopping and stopped training once we had >.8 validation
accuracy.
